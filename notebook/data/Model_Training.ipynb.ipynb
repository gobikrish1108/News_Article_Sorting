{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Importing Necessary Libraries"
      ],
      "metadata": {
        "id": "ihin9Gs9dp1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from keras.callbacks import EarlyStopping\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "tyahMCs7dzJD"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loading Preprocessed Data"
      ],
      "metadata": {
        "id": "6bQL9OENd7K3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('preprocessed_bbc_news.csv')"
      ],
      "metadata": {
        "id": "Y9OAaSgTd_CN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Label Encoding"
      ],
      "metadata": {
        "id": "7LUXMu7iee0K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "df['Category_target'] = label_encoder.fit_transform(df['Category'])\n"
      ],
      "metadata": {
        "id": "gG_yWS0jeg8o"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tokenizing the Text Data"
      ],
      "metadata": {
        "id": "0kLkLHCEepeN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=5000, lower=True)  # num_words=5000 limits the vocab size to 5000 most common words\n",
        "tokenizer.fit_on_texts(df['ProcessedText'])\n",
        "X = tokenizer.texts_to_sequences(df['ProcessedText'])\n"
      ],
      "metadata": {
        "id": "NMQWGRKgernC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Padding the Sequences"
      ],
      "metadata": {
        "id": "28jui1RGe45-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = pad_sequences(X, maxlen=500)"
      ],
      "metadata": {
        "id": "uKm8T-uTe628"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### One-Hot Encoding the Labels"
      ],
      "metadata": {
        "id": "6XuO9AXXfBqo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = to_categorical(df['Category_target'])"
      ],
      "metadata": {
        "id": "bOGZpnAOfDzV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Splitting the Dataset"
      ],
      "metadata": {
        "id": "isgPnkLYfIx4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=30)\n"
      ],
      "metadata": {
        "id": "EVvvadp_fKeV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Building the LSTM Model"
      ],
      "metadata": {
        "id": "VJ3V66xAfS-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=5000, output_dim=128))\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.4))  #\n",
        "model.add(Dense(5, activation='softmax'))\n"
      ],
      "metadata": {
        "id": "yeU0vlsQfVWH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Compiling the Model"
      ],
      "metadata": {
        "id": "qVIjZ-mGgQVS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "YjeW877XgSbn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training the Model"
      ],
      "metadata": {
        "id": "U5a3-XfDgbG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=50,\n",
        "                    batch_size=64,\n",
        "                    validation_split=0.2,\n",
        "                    verbose=1,\n",
        "                    callbacks=[EarlyStopping(monitor='val_loss', patience=7, min_delta=0.01)]\n",
        "                   )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qR8Vxek8gddh",
        "outputId": "94726833-60a7-4da9-8bb4-d4a315ce06f2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 2s/step - accuracy: 0.2384 - loss: 1.6063 - val_accuracy: 0.2427 - val_loss: 1.5765\n",
            "Epoch 2/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2s/step - accuracy: 0.2947 - loss: 1.5817 - val_accuracy: 0.5649 - val_loss: 1.3884\n",
            "Epoch 3/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.5495 - loss: 1.2350 - val_accuracy: 0.6151 - val_loss: 0.8880\n",
            "Epoch 4/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.6872 - loss: 0.8139 - val_accuracy: 0.7950 - val_loss: 0.5085\n",
            "Epoch 5/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 2s/step - accuracy: 0.7884 - loss: 0.5689 - val_accuracy: 0.6695 - val_loss: 0.7577\n",
            "Epoch 6/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3s/step - accuracy: 0.7901 - loss: 0.4997 - val_accuracy: 0.7741 - val_loss: 0.5436\n",
            "Epoch 7/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 3s/step - accuracy: 0.8136 - loss: 0.3957 - val_accuracy: 0.8243 - val_loss: 0.4272\n",
            "Epoch 8/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 2s/step - accuracy: 0.8725 - loss: 0.3199 - val_accuracy: 0.8075 - val_loss: 0.5016\n",
            "Epoch 9/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2s/step - accuracy: 0.9004 - loss: 0.3120 - val_accuracy: 0.8410 - val_loss: 0.4195\n",
            "Epoch 10/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2s/step - accuracy: 0.9351 - loss: 0.2094 - val_accuracy: 0.8661 - val_loss: 0.3942\n",
            "Epoch 11/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2s/step - accuracy: 0.9539 - loss: 0.1778 - val_accuracy: 0.8536 - val_loss: 0.5181\n",
            "Epoch 12/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 2s/step - accuracy: 0.9753 - loss: 0.1253 - val_accuracy: 0.8494 - val_loss: 0.4867\n",
            "Epoch 13/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - accuracy: 0.9863 - loss: 0.0869 - val_accuracy: 0.8410 - val_loss: 0.5564\n",
            "Epoch 14/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2s/step - accuracy: 0.9931 - loss: 0.0615 - val_accuracy: 0.8326 - val_loss: 0.6299\n",
            "Epoch 15/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2s/step - accuracy: 0.9932 - loss: 0.0631 - val_accuracy: 0.8452 - val_loss: 0.6103\n",
            "Epoch 16/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2s/step - accuracy: 0.9879 - loss: 0.0608 - val_accuracy: 0.8368 - val_loss: 0.5993\n",
            "Epoch 17/50\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2s/step - accuracy: 0.9972 - loss: 0.0448 - val_accuracy: 0.8410 - val_loss: 0.6127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluating the Model"
      ],
      "metadata": {
        "id": "td_qPEqQguGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
        "print(f'Test Accuracy: {accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyvCV9G_gzeV",
        "outputId": "5179aa73-0162-46cf-f4b4-3ec7344f864c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 350ms/step - accuracy: 0.8624 - loss: 0.6610\n",
            "Test Accuracy: 86.58%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Function to Predict Category for New Text"
      ],
      "metadata": {
        "id": "W-NCFrXchChH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_category(text):\n",
        "    # Convert the input text to sequence and pad it to match the model input shape\n",
        "    seq = tokenizer.texts_to_sequences([text])\n",
        "    padded = pad_sequences(seq, maxlen=500)\n",
        "\n",
        "    # Predict the category and return the corresponding label\n",
        "    pred = model.predict(padded)\n",
        "    return label_encoder.inverse_transform([np.argmax(pred)])\n"
      ],
      "metadata": {
        "id": "nFwtibLzhIGZ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Testing the Prediction"
      ],
      "metadata": {
        "id": "Np0cM_5thRhp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_text = \"While people on social media have been amused by Arshad Nadeem being gifted a buffalo for winning gold at Paris Olympics.\"\n",
        "category = predict_category(new_text)\n",
        "print(f'Predicted Category: {category}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okEf5lt7hVuT",
        "outputId": "37e3749b-5f14-4c15-b32c-c325df348fc6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426ms/step\n",
            "Predicted Category: ['business']\n"
          ]
        }
      ]
    }
  ]
}